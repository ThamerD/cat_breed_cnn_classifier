{
  "hash": "60687b2f391d85a7fab5a9371d55af3a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Cat breed CNN classifier\njupyter: python3\nauthor: \"Thamer Aldawood\"\ndate: \"2025-02-23\"\ncategories: [ML Models, Guides, Code, PyTorch, Neural Networks]\nimage: \"cover.png\"\ntoc: true\ntoc-depth: 4\n---\n\n\n\n\nThis is a Convolutional Neural Network (CNN) that classifies cats based on their images into one of 6 breeds:\n1. American Short hair  \n2. Bengal  \n3. Maine Soon  \n4. Ragdoll  \n5. Scottish Fold  \n6. Sphinx  \n   \nWe will leverage PyTorch for this task.\n\n\n## Preamble: The dataset\nWe will be using the following public Kaggle dataset: https://www.kaggle.com/datasets/solothok/cat-breed \nIt contains training data which has 200 images for each class and test data that has 50 images for each class.\n\n## Imports\n<hr>\n\n::: {#58e8fa1b .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.284882Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.284574Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.289736Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.288670Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.284855Z\"}' execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nfrom collections import OrderedDict\nimport torch\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms, utils, models\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom PIL import Image\n\nplt.rcParams.update({'axes.grid': False})\n```\n:::\n\n\nCNNs are comupationally demanding to run. Ideally, we want to utilize a GPU to improve our performance instead of a CPU. The following code snippet checks that our GPU and Pytorch setup is working.\n\n::: {#c207a193 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.291394Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.291084Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.302910Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.302090Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.291362Z\"}' execution_count=2}\n``` {.python .cell-code}\ntorch.cuda.is_available()\n```\n:::\n\n\n::: {#bb257de2 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.304457Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.304191Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.313565Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.312866Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.304437Z\"}' execution_count=3}\n``` {.python .cell-code}\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU (CUDA) if available, else use CPU\nprint(f\"Using device: {device.type}\")\n```\n:::\n\n\n## 1. CNN from scratch\nFirst, let's try to make a CNN from scratch for this task, and see how well it performs (spoiler: it won't be anywhere near as good as pre-trained models). This will also helps us understand how CNNs work and how we can adapt them to different tasks.\n\n### 1.1 Read the data\nWe simply need to set the paths to our training and test sets. Keep in mind that we are not actually reading the data yet, just learning where it is.\n\n::: {#f11749d6 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.314972Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.314698Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.323877Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.323044Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.314945Z\"}' tags='[]' execution_count=4}\n``` {.python .cell-code}\nimport torchvision\n\nTRAIN_DIR = \"/kaggle/input/cat-breed/cat-breed/TRAIN\"\nTEST_DIR = \"/kaggle/input/cat-breed/cat-breed/TEST\"\n```\n:::\n\n\n::: {#357fc544 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.325381Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.325102Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.335929Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.335148Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.325361Z\"}' tags='[]' execution_count=5}\n``` {.python .cell-code}\nprint(f\"Classes: {train_dataset.classes}\")\nprint(f\"Class count: {train_dataset.targets.count(0)}, {train_dataset.targets.count(1)}\")\nprint(f\"Samples:\",len(train_dataset))\nprint(f\"First sample: {train_dataset.samples[0]}\")\n```\n:::\n\n\n### 1.2 Transform images\nThe images in our dataset have all kinds of different resolutions and aspect ratios, we must normalize them to a specific shape and size to be able to work with them. We will tranform them into 200x200 images.\n\n::: {#f63d486a .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.337334Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.337007Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.356763Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.356197Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.337305Z\"}' metadata='{\"tags\":[\"otter_ignore\"]}' tags='[]' execution_count=6}\n``` {.python .cell-code}\nIMAGE_SIZE = (200, 200) # This does not depend on the size of the raw images\n\ndata_transforms = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = torchvision.datasets.ImageFolder(root=TRAIN_DIR, transform=data_transforms)\ntest_dataset = torchvision.datasets.ImageFolder(root=TEST_DIR, transform=data_transforms)\n```\n:::\n\n\n### 1.3 Create batches\nOur dataset is too large to be loaded all at once, we must instead create loaders to feed the data into our model in batches.\n\n::: {#382b6088 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.357811Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.357541Z\"}' metadata='{\"tags\":[\"otter_ignore\"]}' tags='[]' execution_count=7}\n``` {.python .cell-code}\nBATCH_SIZE = 64\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,          \n    batch_size=BATCH_SIZE,  \n    shuffle=True,           \n)\n\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,          \n    batch_size=BATCH_SIZE,  \n    shuffle=True,          \n)\n```\n:::\n\n\n::: {#ed22224e .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.364562Z\",\"iopub.status.idle\":\"2025-02-24T02:59:41.683684Z\",\"shell.execute_reply\":\"2025-02-24T02:59:41.682810Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.364542Z\"}' execution_count=8}\n``` {.python .cell-code}\n# (Optional) Checking our batches\n\nimgs, targets = next(iter(train_loader))\n\nprint(f\"  Number of batches: {len(train_loader)}\")\nprint(f\"    Image data type: {type(imgs)}\")\nprint(f\"   Image batch size: {imgs.shape}\") \nprint(f\"  Target batch size: {targets.shape}\")\n```\n:::\n\n\n::: {#b9767456 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:41.685166Z\",\"iopub.status.busy\":\"2025-02-24T02:59:41.684849Z\",\"iopub.status.idle\":\"2025-02-24T02:59:43.560337Z\",\"shell.execute_reply\":\"2025-02-24T02:59:43.559415Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:41.685134Z\"}' execution_count=9}\n``` {.python .cell-code}\n# A sample of our training data\n\nsample_batch = next(iter(train_loader))\nplt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\nplt.imshow(np.transpose(torchvision.utils.make_grid(sample_batch[0], padding=1, normalize=True),(1,2,0)));\n```\n:::\n\n\n### 1.4 Create the CNN\nNow, the fun part. We design a CNN using various functions from the Pytorch package. There is no right or wrong here, we simply experiment with different configuration until we reach a suitabel model.\n\n::: {#8893a37b .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:43.561726Z\",\"iopub.status.busy\":\"2025-02-24T02:59:43.561316Z\",\"iopub.status.idle\":\"2025-02-24T02:59:43.570222Z\",\"shell.execute_reply\":\"2025-02-24T02:59:43.569424Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:43.561687Z\"}' execution_count=10}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\n\nclass cat_CNN(nn.Module):\n    def __init__(self):\n        super(cat_CNN, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n            nn.Dropout(0.2),\n\n            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n            nn.Dropout(0.5),\n\n            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n            nn.Dropout(0.2),\n\n            nn.Conv2d(128, 256, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n            nn.Dropout(0.2),\n\n            nn.Flatten(),\n            \n            nn.Linear(256 * 12 * 12, 512),\n            nn.ReLU(),\n\n            nn.Linear(512, 128),\n            nn.ReLU(),\n\n            nn.Linear(128, 6)\n        )\n        \n    def forward(self, x):\n        return self.model(x)\n\n```\n:::\n\n\n### 1.5 Train the model\nIt is time to train the model. In the function below, not only do we train the model, we also evaluate it after every epoch. This is useful for continuously observing the performance of our model, and can help us decide if we need to change the number of epochs, or adjust certain aspects of our model that may be causing overfitting, etc.  \nNote: Training CNNs is computationally demanding. I am using Kaggle's GPU T4 x 2 accelerator to improve performance.\n\n::: {#4884a033 .cell execution='{\"iopub.execute_input\":\"2025-02-24T02:59:43.571458Z\",\"iopub.status.busy\":\"2025-02-24T02:59:43.571107Z\",\"iopub.status.idle\":\"2025-02-24T02:59:43.581247Z\",\"shell.execute_reply\":\"2025-02-24T02:59:43.580463Z\",\"shell.execute_reply.started\":\"2025-02-24T02:59:43.571425Z\"}' execution_count=11}\n``` {.python .cell-code}\ndef trainer(model, criterion, optimizer, trainloader, validloader, epochs=5, verbose=True):\n    \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n    \n    train_loss, valid_loss, valid_accuracy = [], [], []\n    for epoch in range(epochs):  # for each epoch\n        train_batch_loss = 0\n        valid_batch_loss = 0\n        valid_batch_acc = 0\n        \n        # Training\n        model.train()\n        for X, y in trainloader:\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_hat = model(X)\n            loss = criterion(y_hat, y)\n            loss.backward()\n            optimizer.step()\n            train_batch_loss += loss.item()\n        train_loss.append(train_batch_loss / len(trainloader))\n        \n        # Validation\n        model.eval()\n        \n        with torch.no_grad():  # this stops pytorch doing computational graph stuff under-the-hood\n            for X, y in validloader:\n                X, y = X.to(device), y.to(device)\n                y_hat = model(X)\n                _, y_hat_labels = torch.softmax(y_hat, dim=1).topk(1, dim=1)\n                loss = criterion(y_hat, y)\n                valid_batch_loss += loss.item()\n                valid_batch_acc += (y_hat_labels.squeeze() == y).type(torch.float32).mean().item()\n        valid_loss.append(valid_batch_loss / len(validloader))\n        valid_accuracy.append(valid_batch_acc / len(validloader))  # accuracy\n        \n\n        \n        # Print progress\n        if verbose:\n            print(f\"Epoch {epoch + 1}:\",\n                  f\"Train Loss: {train_loss[-1]:.3f}.\",\n                  f\"Valid Loss: {valid_loss[-1]:.3f}.\",\n                  f\"Valid Accuracy: {valid_accuracy[-1]:.2f}.\")\n    \n    results = {\"train_loss\": train_loss,\n               \"valid_loss\": valid_loss,\n               \"valid_accuracy\": valid_accuracy}\n    return results    \n```\n:::\n\n\n::: {#c52219b8 .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:15:58.186488Z\",\"iopub.status.busy\":\"2025-02-24T03:15:58.186146Z\",\"iopub.status.idle\":\"2025-02-24T03:20:26.359930Z\",\"shell.execute_reply\":\"2025-02-24T03:20:26.359205Z\",\"shell.execute_reply.started\":\"2025-02-24T03:15:58.186462Z\"}' execution_count=12}\n``` {.python .cell-code}\n# Training the model and observing its results\n\ncat_model = cat_CNN().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(cat_model.parameters(), lr=1e-3)\n\ntorch.manual_seed(792)\n\nresults = trainer(cat_model, criterion, optimizer, train_loader, test_loader, epochs=20)\n```\n:::\n\n\nWe can see that our humble from-scratch model is able to correctly classify cat breeds approximately half the time. We can do a lot better by leveraging pre-trained models as we will explore in the next section.\n\n## 2. Pre-trained models\nWe will explore how we can leverage pre-trained models to improve our model's performance. We will use DenseNet to extract features from our images, then feed it to our model to finally classify them.\n\n### 2.1 Pre-trained model as-is\nThe simplest way to use a pre-trained model is to use it as-is, let's try that and see how it performs then decide whether or not we want to fine-tune it for our use case.\n\n::: {#b2a3a11b .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:05:14.039174Z\",\"iopub.status.busy\":\"2025-02-24T03:05:14.038756Z\",\"iopub.status.idle\":\"2025-02-24T03:05:14.245230Z\",\"shell.execute_reply\":\"2025-02-24T03:05:14.244294Z\",\"shell.execute_reply.started\":\"2025-02-24T03:05:14.039144Z\"}' metadata='{\"tags\":[\"otter_ignore\"]}' tags='[]' execution_count=13}\n``` {.python .cell-code}\ndensenet = models.densenet121(pretrained=True)\n\nfor param in densenet.parameters():  # Freeze parameters so we don't update them (Keep model as-is)\n    param.requires_grad = False\n\ndensenet.classifier\n```\n:::\n\n\n::: {#e236bda9 .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:05:14.885891Z\",\"iopub.status.busy\":\"2025-02-24T03:05:14.885625Z\",\"iopub.status.idle\":\"2025-02-24T03:05:14.892221Z\",\"shell.execute_reply\":\"2025-02-24T03:05:14.891543Z\",\"shell.execute_reply.started\":\"2025-02-24T03:05:14.885870Z\"}' execution_count=14}\n``` {.python .cell-code}\n# Our classification layer\ncustom_classification_layer = nn.Sequential(\n    nn.Linear(1024, 50),\n    nn.ReLU(),\n    nn.Linear(50, 6)\n)\n\ndensenet.classifier = custom_classification_layer\n\ndensenet.classifier\n```\n:::\n\n\nNote: The DenseNet model is much larger and more complex than our scratch-made model. It is very computationally demanding.\n\n::: {#68fa78d7 .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:05:19.281556Z\",\"iopub.status.busy\":\"2025-02-24T03:05:19.281270Z\",\"iopub.status.idle\":\"2025-02-24T03:05:19.316292Z\",\"shell.execute_reply\":\"2025-02-24T03:05:19.315636Z\",\"shell.execute_reply.started\":\"2025-02-24T03:05:19.281532Z\"}' execution_count=15}\n``` {.python .cell-code}\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device.type}\")\n\ndensenet.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(densenet.parameters(), lr=1e-3)\n```\n:::\n\n\n::: {#e6e2fe2d .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:05:20.377505Z\",\"iopub.status.busy\":\"2025-02-24T03:05:20.377217Z\",\"iopub.status.idle\":\"2025-02-24T03:07:50.960134Z\",\"shell.execute_reply\":\"2025-02-24T03:07:50.959221Z\",\"shell.execute_reply.started\":\"2025-02-24T03:05:20.377480Z\"}' execution_count=16}\n``` {.python .cell-code}\nresults = trainer(densenet, criterion, optimizer, train_loader, test_loader, epochs=10)\n```\n:::\n\n\nAfter leveraging the pre-trained model, our performance has become very impressive. Our model can now correctly classify cat breeds based on their images 92% of the time.\n\n### 2.2: Fine-tuned pre-trained model\n\nThe DenseNet model is incredible, but it is forced to make certain compromises to generalize for different tasks. Let's try to fine-tune it so that it performs better for our specific cat breed classification task.  \nThere are plenty of ways to fine-tune a pre-trained model. In our case, we will explore 2 fine-tuning methods:  \n1. Fully unfrozen pre-trained model.\n2. Partially unfrozen pre-trained model.\n\n#### 2.2.1 Fully unfrozen pre-trained model\nThis fine-tuning method throws away all of the learned parameters from the pre-trained model, and generates new ones by training it on our dataset. Essentially, it uses the architecture of the pre-trained model but throws away all of its previous training.\n\n::: {#0046bf1f .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:08:31.880760Z\",\"iopub.status.busy\":\"2025-02-24T03:08:31.880454Z\",\"iopub.status.idle\":\"2025-02-24T03:08:32.060701Z\",\"shell.execute_reply\":\"2025-02-24T03:08:32.059759Z\",\"shell.execute_reply.started\":\"2025-02-24T03:08:31.880737Z\"}' execution_count=17}\n``` {.python .cell-code}\ndensenet_ft_full = models.densenet121(pretrained=True)\nfor param in densenet_ft_full.parameters():\n    # Freeze parameters so we don't update them\n    param.requires_grad = False\n\ndensenet_ft_full.classifier = custom_classification_layer # replace classification layer with ours\n```\n:::\n\n\n::: {#5fd37d22 .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:08:33.070754Z\",\"iopub.status.busy\":\"2025-02-24T03:08:33.070444Z\",\"iopub.status.idle\":\"2025-02-24T03:11:04.717030Z\",\"shell.execute_reply\":\"2025-02-24T03:11:04.716337Z\",\"shell.execute_reply.started\":\"2025-02-24T03:08:33.070731Z\"}' execution_count=18}\n``` {.python .cell-code}\ndensenet_ft_full.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(densenet_ft_full.parameters(), lr=1e-3)\nresults = trainer(densenet_ft_full, criterion, optimizer, train_loader, test_loader, epochs=10)\n```\n:::\n\n\nWe can see that the fully unfrozen pre-trained model performs very similarly to the as-is pre-trained model. This is mostly coincidental. Let's see if we can do better.\n\n#### 2.2.2 Partially unfrozen pre-trained model\nThis fine-tuning method throws keeps almost everything from the pre-trained model, but fine-tunes a few of its layers (usually the last) to work better for our use case. These models should take less time to train as we're only training a few layers rather than training all of them.\n\n::: {#216d8fab .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:11:30.547720Z\",\"iopub.status.busy\":\"2025-02-24T03:11:30.547425Z\",\"iopub.status.idle\":\"2025-02-24T03:11:30.729325Z\",\"shell.execute_reply\":\"2025-02-24T03:11:30.728563Z\",\"shell.execute_reply.started\":\"2025-02-24T03:11:30.547699Z\"}' metadata='{\"tags\":[\"otter_ignore\"]}' tags='[]' execution_count=19}\n``` {.python .cell-code}\ndensenet_ft_partial = models.densenet121(pretrained=True)\nfor layer in densenet_ft_partial.features[:-1]: # Freezing all but last layer\n    for param in layer.parameters():\n        param.requires_grad = False\n\ndensenet_ft_partial.classifier = custom_classification_layer\n```\n:::\n\n\n::: {#ffc36d99 .cell execution='{\"iopub.execute_input\":\"2025-02-24T03:11:31.395431Z\",\"iopub.status.busy\":\"2025-02-24T03:11:31.395169Z\",\"iopub.status.idle\":\"2025-02-24T03:14:03.612422Z\",\"shell.execute_reply\":\"2025-02-24T03:14:03.611699Z\",\"shell.execute_reply.started\":\"2025-02-24T03:11:31.395410Z\"}' execution_count=20}\n``` {.python .cell-code}\n# Train the model\ndensenet_ft_partial.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(densenet_ft_partial.parameters(), lr=1e-3)\nresults = trainer(densenet_ft_partial, criterion, optimizer, train_loader, test_loader, epochs=10)\n```\n:::\n\n\n### Recap:  \n\n1. From-scratch model performance: ~0.54 validation accuracy.\n2. Densenet as-is model performance: ~0.92 validation accuracy.\n3. Densenet fully unfrozen model performance: ~0.92 validation accuracy.\n4. Densenet partially frozen model performance: ~0.93 validation accuracy.\n\nAlthough additional fine-tuning is possible, we will likely get diminishing returns.\n\nIt is very interesting that the partially frozen model performed better than the fully unfrozen model. This suggests that the default weights of the densenet model are better than the weights we are creating as a result of training on our dataset. This makes sense because those default weights were likely created through much more training on much larger datasets. It is impressive that those default weights perform so well on our specific case even though they weren't created with classifying cat breeds in mind (it may have been part of its training, but definitely not the entire focus).\n\n",
    "supporting": [
      "cat_breed_cnn_classifier_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}